# -*- coding: utf-8 -*-
"""HCNN_VGG16_SVM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JlL94cgU7hRRLrdXOA7Xd-jbczdlaT84

# **Programa de Pós-graduação em Engenharia Elétrica e Computação (PPGEEC/UFC)**

## Tema: ``Otimização dos Hiperparâmetros de uma Rede Neural Convolucional Híbrida Utilizando Algoritmos Genéticos para Classificação de Defeitos em Imagens Eletroluminescentes de Células Fotovoltaicas``.

### **Divisão do Projeto:**

- **Seção 1** - Importação das Bibliotecas e Acesso à Base de Dados das Imagens; (**``Etapa finalizada!!``**) ✅

- **Seção 2** - Acesso e manipulação de Dados e Imagens (**``Etapa finalizada!!``**) ✅

- **Seção 3** - Implementação da CNN do tipo VGG16 pré-treinada com ImageNet; (**``Etapa finalizada!!``**) ✅

- **Seção 4** - Implementação da Máquina de Vetor de Suporte para classificação dos defeitos; (**``Etapa finalizada!!``**) ✅

- **Seção 5** - Análise dos resultados. (**``Etapa finalizada!!``**) ✅

## **Seção 1. - Importação das Bibliotecas e Acesso à Base de Dados de Imagens** (**``Etapa finalizada!!``**) ✅
---
Nesta Seção são realizadas as importações da bibliotecas para manipulação das imagens, assim como para acesso à base de dados diretamente pelo GDrive.

#### Bibliotecas necessárias para a abertura da base de dados e ligação do Google Drive com o Colab
"""

import glob
from google.colab import drive
drive.mount('/content/drive')

"""#### Bibliotecas necessárias para a manipulação de dados, vetores, strings, plotagem de imagens, etc."""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import os
import random
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

"""#### Bibliotecas necessárias para importação da CNN e SVM"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten
import tensorflow as tf

from sklearn.svm import SVC

"""#### Bibliotecas necessárias para treinamento do modelo e obtenção das métricas de avaliação:

"""

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, cohen_kappa_score
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.model_selection import GridSearchCV

"""## **Seção 2. - Acesso e manipulação de Dados e Imagens (**``Etapa finalizada!!``**) ✅

### **Seção 2.1 - Acesso à Base de Dados**
"""

# Realiza a cópia da base de dados com 2.624 imagens já com a técnica CLAHE aplicada.
!cp -r /content/drive/MyDrive/__ppgeec_mestrado/_dissertação/_base_de_dados/data_base_clahe_reduced /content/dataset

print("Operação finalizada!!")

# Realiza a cópia do arquivo contendo o rótulo das imagens para a pasta dataset
!cp -r /content/drive/MyDrive/__ppgeec_mestrado/_dissertação/_base_de_dados/labels_data_base_clahe_reduced.csv /content/dataset

print('Operação finalizada!!')

"""### **Seção 2.2 - Acesso as imagens e seus respectivos rótulos.**"""

images = '/content/dataset'

labels = pd.read_csv('/content/dataset/labels_data_base_clahe_reduced.csv', sep=';')

print('Operação finalizada!!')

labels

# Verificar os nomes das colunas do CSV
print("Colunas disponíveis no CSV:", labels.columns)

"""### **Seção 2.3 - Redimensionando as imagens para 224 $\times$ 224**
---
"""

# Cria o diretório para armazenar as imagens CLAHE em níveis de cinza
output_dir = '/content/dataset_reduced'
os.makedirs(output_dir, exist_ok = True)

# Diretório onde as imagens originais estão localizadas
diretorio_originais = images

# Diretório onde você deseja salvar as imagens redimensionadas
diretorio_redimensionadas = "/content/dataset_reduced"

# Certifique-se de que o diretório de saída existe
if not os.path.exists(diretorio_redimensionadas):
    os.makedirs(diretorio_redimensionadas)

# Tamanho de destino para redimensionamento (224x224 pixels para VGG16)
target_size = (224, 224)

# Lista todos os arquivos no diretório de originais
arquivos = os.listdir(diretorio_originais)

# Itera sobre os arquivos e redimensiona cada imagem
for arquivo in arquivos:
    # Verifica se o arquivo tem uma extensão de imagem (por exemplo, .jpg, .jpeg, .png, .gif, .bmp)
    if arquivo.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp')):
        # Caminho completo do arquivo de entrada (original)
        caminho_originais = os.path.join(diretorio_originais, arquivo)

        # Carrega a imagem original
        imagem_original = cv2.imread(caminho_originais)

        # Redimensiona a imagem para o tamanho de destino
        imagem_redimensionada = cv2.resize(imagem_original, target_size)

        # Caminho completo do arquivo de saída (redimensionado)
        caminho_redimensionadas = os.path.join(diretorio_redimensionadas, arquivo)

        # Salva a imagem redimensionada no diretório de saída
        cv2.imwrite(caminho_redimensionadas, imagem_redimensionada)

print("Redimensionamento concluído. As imagens foram salvas em:", diretorio_redimensionadas)

# Realiza a cópia do arquivo contendo o rótulo das imagens para a pasta dataset
!cp -r /content/drive/MyDrive/__ppgeec_mestrado/_dissertação/_base_de_dados/labels_data_base_clahe_reduced.csv /content/dataset_reduced

print('Operação finalizada!!')

labels_reduced = pd.read_csv('/content/dataset_reduced/labels_data_base_clahe_reduced.csv', sep=';')

labels_reduced

"""## **Seção 3. - Implementação da CNN do tipo VGG16 pré-treinada com ImageNet** (**``Etapa finalizada!!``**) ✅"""

# Carregar o CSV com os rótulos
labels = labels_reduced

# Função para carregar e pré-processar as imagens
def load_and_preprocess_image(image_path):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image)
    image = preprocess_input(image)
    return image

# Carregar e pré-processar todas as imagens
image_paths = labels['image'].apply(lambda x: os.path.join('/content/dataset_reduced', x))
images = np.array([load_and_preprocess_image(img_path) for img_path in image_paths])
labels = labels['prob_defect'].values

# Dividir os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)

# Carregar o modelo VGG-16 pré-treinado
base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Congelar as camadas do modelo base
for layer in base_model.layers:
    layer.trainable = False

# Adicionar a camada de flattening
x = base_model.output
x = tf.keras.layers.Flatten()(x)
model = Model(inputs=base_model.input, outputs=x)

# Extrair características das imagens de treino e teste
X_train_features = model.predict(X_train)
X_test_features = model.predict(X_test)

# Definir o classificador SVM e os hiperparâmetros para a busca
svm = SVC()
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': ['scale', 'auto'],
    'kernel': ['linear', 'rbf', 'poly']
}

# Realizar a busca de hiperparâmetros com validação cruzada
grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)
grid_search.fit(X_train_features, y_train)

# Obter os melhores parâmetros
best_svm = grid_search.best_estimator_
print(f'Melhores parâmetros da SVM: {grid_search.best_params_}')

# Fazer previsões no conjunto de teste
y_pred = best_svm.predict(X_test_features)

# Função para plotar a matriz de confusão
def plot_confusion_matrix(conf_matrix, class_names):
    plt.figure(figsize=(10, 7))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='gray', xticklabels=class_names, yticklabels=class_names)
    plt.xlabel('Rótulo predito')
    plt.ylabel('Rótulo verdadeiro')
    plt.title('Matriz de Confusão')
    plt.show()

# Plotar a matriz de confusão
plot_confusion_matrix(conf_matrix, class_names)

# Calcular as métricas
accuracy = accuracy_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)
report = classification_report(y_test, y_pred, output_dict=True)
kappa = cohen_kappa_score(y_test, y_pred)

# Resultados
print(f'Accuracy: {accuracy:.4f}')
print(f'Kappa: {kappa:.4f}')
print(f'Precision: {report["weighted avg"]["precision"]:.4f}')
print(f'Recall: {report["weighted avg"]["recall"]:.4f}')
print(f'F1-score: {report["weighted avg"]["f1-score"]:.4f}')
print(f'Confusion Matrix:\n {conf_matrix}')

# Calcular acurácia com desvio padrão usando validação cruzada
cross_val_scores = cross_val_score(svm, X_train_features, y_train, cv=5)
print(f'Cross-validated accuracy: {cross_val_scores.mean():.4f} ± {cross_val_scores.std():.4f}')

# Função para plotar imagens com rótulos verdadeiros e preditos
def plot_images(images, true_labels, pred_labels, class_names, num_images=10):
    plt.figure(figsize=(20, 10))
    for i in range(num_images):
        ax = plt.subplot(2, num_images // 2, i + 1)
        plt.imshow(images[i].astype('uint8'))
        true_label = class_names[true_labels[i]]
        pred_label = class_names[pred_labels[i]]
        plt.title(f'True: {true_label}\nPred: {pred_label}')
        plt.axis('off')

# Definir nomes das classes
class_names = ['Sem defeito', 'Com defeito']

# Selecionar algumas imagens do conjunto de teste para visualização
num_images_to_plot = 10
plot_images(X_test[:num_images_to_plot], y_test[:num_images_to_plot], y_pred[:num_images_to_plot], class_names, num_images=num_images_to_plot)
plt.show()